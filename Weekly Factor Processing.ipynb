{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bayesian Writing Sample Factor Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methodology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Data source: WRDS\n",
    "from wrds import Connection\n",
    "\n",
    "# Data output\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_weekly(df):\n",
    "    \"\"\"\n",
    "    Convert daily financial data to weekly, starting from 2010/01/03\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame with date index and financial metrics\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Weekly resampled data\n",
    "    \"\"\"\n",
    "    # Convert the 'date' column to datetime if it's not already\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    \n",
    "    # Set date as index\n",
    "    df = df.set_index('date')\n",
    "    \n",
    "    # Resample to weekly frequency (week ending on Sunday)\n",
    "    # Using last() to get the last value of each week\n",
    "    weekly_data = df.resample('W-SUN').last()\n",
    "    \n",
    "    # Reset index to make date a column again\n",
    "    weekly_data = weekly_data.reset_index()\n",
    "    \n",
    "    return weekly_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def slice_data(df, start_date='2010/01/03', end_date='2019/12/29'):\n",
    "    \"\"\"\n",
    "    Slice the data between specified start and end dates\n",
    "    \n",
    "    Parameters:\n",
    "    df (pandas.DataFrame): DataFrame with 'date' column\n",
    "    start_date (str): Start date in YYYY/MM/DD format\n",
    "    end_date (str): End date in YYYY/MM/DD format\n",
    "    \n",
    "    Returns:\n",
    "    pandas.DataFrame: Sliced data\n",
    "    \"\"\"\n",
    "    # Create a copy of the dataframe\n",
    "    df = df.copy()\n",
    "    \n",
    "    # Convert dates to datetime for comparison\n",
    "    df['date'] = pd.to_datetime(df['date'])\n",
    "    start_date = pd.to_datetime(start_date)\n",
    "    end_date = pd.to_datetime(end_date)\n",
    "    \n",
    "    # Slice the data\n",
    "    mask = (df['date'] >= start_date) & (df['date'] <= end_date)\n",
    "    sliced_data = df.loc[mask].copy()  # Create explicit copy of the slice\n",
    "    \n",
    "    # Convert dates back to string format\n",
    "    sliced_data['date'] = sliced_data['date'].dt.strftime('%Y/%m/%d')\n",
    "    \n",
    "    return sliced_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fama French 5 Factors Plus Momentum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data source: WRDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date   mktrf     smb     hml     rmw     cma       rf     umd\n",
      "4    2010/01/03 -0.0099 -0.0017  0.0039 -0.0047  0.0017  0.00000  0.0003\n",
      "5    2010/01/10  0.0033  0.0032  0.0001  0.0022 -0.0037  0.00000  0.0020\n",
      "6    2010/01/17 -0.0112 -0.0019 -0.0039  0.0061 -0.0015  0.00000 -0.0052\n",
      "7    2010/01/24 -0.0214  0.0051 -0.0089  0.0046  0.0000  0.00000 -0.0158\n",
      "8    2010/01/31 -0.0097 -0.0008 -0.0042 -0.0020  0.0018  0.00000 -0.0124\n",
      "..          ...     ...     ...     ...     ...     ...      ...     ...\n",
      "521  2019/12/01 -0.0042 -0.0011 -0.0031 -0.0047  0.0000  0.00006 -0.0001\n",
      "522  2019/12/08  0.0091  0.0038  0.0037  0.0033  0.0022  0.00007 -0.0076\n",
      "523  2019/12/15 -0.0003 -0.0045 -0.0055 -0.0027 -0.0024  0.00007  0.0076\n",
      "524  2019/12/22  0.0048 -0.0027 -0.0031  0.0001 -0.0007  0.00007  0.0023\n",
      "525  2019/12/29 -0.0010 -0.0055 -0.0007  0.0026  0.0010  0.00007  0.0037\n",
      "\n",
      "[522 rows x 8 columns]\n"
     ]
    }
   ],
   "source": [
    "FF5M = pd.read_csv('data\\FamaFrenchPlusMomentum.csv')\n",
    "FF5M = convert_to_weekly(FF5M)\n",
    "FF5M = slice_data(FF5M)\n",
    "\n",
    "print(FF5M)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Q-factors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Source: WRDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Connection' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Connect to WRDS\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m conn \u001b[38;5;241m=\u001b[39m Connection()\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# Run your query\u001b[39;00m\n\u001b[0;32m      5\u001b[0m Q_Factors \u001b[38;5;241m=\u001b[39m conn\u001b[38;5;241m.\u001b[39mraw_sql(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mSELECT * FROM macrofin.q_factors_daily\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Connection' is not defined"
     ]
    }
   ],
   "source": [
    "# Connect to WRDS\n",
    "conn = Connection()\n",
    "\n",
    "# Run your query\n",
    "Q_Factors = conn.raw_sql(\"SELECT * FROM macrofin.q_factors_daily\")\n",
    "\n",
    "# Save to a CSV file if desired\n",
    "# Close the connection\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            date     r_f   r_mkt    r_me    r_ia   r_roe    r_eg\n",
      "2243  2010/01/03  0.0003 -0.8664 -0.0883  0.1901 -0.0024 -0.0776\n",
      "2244  2010/01/10  0.0001  0.4160  0.2017 -0.4278 -0.1254  0.0851\n",
      "2245  2010/01/17  0.0001 -1.1324 -0.2926 -0.0268  0.4190  0.2474\n",
      "2246  2010/01/24  0.0001 -2.0990  0.2744  0.0938  0.1175 -0.4539\n",
      "2247  2010/01/31  0.0001 -1.0283  0.0259  0.3848  0.2150 -0.2583\n",
      "...          ...     ...     ...     ...     ...     ...     ...\n",
      "2760  2019/12/01  0.0060 -0.4105 -0.1160 -0.0309 -0.1402 -0.0431\n",
      "2761  2019/12/08  0.0068  0.8357  0.3910  0.1494 -0.2265 -0.1986\n",
      "2762  2019/12/15  0.0068 -0.0037 -0.5008 -0.3819  0.0556  0.3914\n",
      "2763  2019/12/22  0.0068  0.4472 -0.4079  0.0509  0.0721  0.1331\n",
      "2764  2019/12/29  0.0068 -0.0711 -0.5205  0.0495  0.3771  0.2624\n",
      "\n",
      "[522 rows x 7 columns]\n"
     ]
    }
   ],
   "source": [
    "Q_Factors = convert_to_weekly(Q_Factors)\n",
    "Q_Factors = slice_data(Q_Factors)\n",
    "print(Q_Factors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combination and Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           date   mktrf     smb     hml     rmw     cma       rf     umd  \\\n",
      "0    2010/01/03 -0.0099 -0.0017  0.0039 -0.0047  0.0017  0.00000  0.0003   \n",
      "1    2010/01/10  0.0033  0.0032  0.0001  0.0022 -0.0037  0.00000  0.0020   \n",
      "2    2010/01/17 -0.0112 -0.0019 -0.0039  0.0061 -0.0015  0.00000 -0.0052   \n",
      "3    2010/01/24 -0.0214  0.0051 -0.0089  0.0046  0.0000  0.00000 -0.0158   \n",
      "4    2010/01/31 -0.0097 -0.0008 -0.0042 -0.0020  0.0018  0.00000 -0.0124   \n",
      "..          ...     ...     ...     ...     ...     ...      ...     ...   \n",
      "517  2019/12/01 -0.0042 -0.0011 -0.0031 -0.0047  0.0000  0.00006 -0.0001   \n",
      "518  2019/12/08  0.0091  0.0038  0.0037  0.0033  0.0022  0.00007 -0.0076   \n",
      "519  2019/12/15 -0.0003 -0.0045 -0.0055 -0.0027 -0.0024  0.00007  0.0076   \n",
      "520  2019/12/22  0.0048 -0.0027 -0.0031  0.0001 -0.0007  0.00007  0.0023   \n",
      "521  2019/12/29 -0.0010 -0.0055 -0.0007  0.0026  0.0010  0.00007  0.0037   \n",
      "\n",
      "        r_f   r_mkt    r_me    r_ia   r_roe    r_eg  \n",
      "0    0.0003 -0.8664 -0.0883  0.1901 -0.0024 -0.0776  \n",
      "1    0.0001  0.4160  0.2017 -0.4278 -0.1254  0.0851  \n",
      "2    0.0001 -1.1324 -0.2926 -0.0268  0.4190  0.2474  \n",
      "3    0.0001 -2.0990  0.2744  0.0938  0.1175 -0.4539  \n",
      "4    0.0001 -1.0283  0.0259  0.3848  0.2150 -0.2583  \n",
      "..      ...     ...     ...     ...     ...     ...  \n",
      "517  0.0060 -0.4105 -0.1160 -0.0309 -0.1402 -0.0431  \n",
      "518  0.0068  0.8357  0.3910  0.1494 -0.2265 -0.1986  \n",
      "519  0.0068 -0.0037 -0.5008 -0.3819  0.0556  0.3914  \n",
      "520  0.0068  0.4472 -0.4079  0.0509  0.0721  0.1331  \n",
      "521  0.0068 -0.0711 -0.5205  0.0495  0.3771  0.2624  \n",
      "\n",
      "[522 rows x 14 columns]\n"
     ]
    }
   ],
   "source": [
    "# Drop the 'date' column from Q_Factors\n",
    "Q_Factors = Q_Factors.drop(columns=['date'])\n",
    "\n",
    "# Ensure both DataFrames have the same number of rows\n",
    "if len(Q_Factors) != len(FF5M):\n",
    "    print(\"Warning: The two DataFrames have different lengths!\")\n",
    "    # Adjust to the minimum length\n",
    "    min_len = min(len(Q_Factors), len(FF5M))\n",
    "    Q_Factors = Q_Factors.iloc[:min_len]\n",
    "    FF5M = FF5M.iloc[:min_len]\n",
    "\n",
    "# Concatenate the DataFrames side by side (excluding the date column from Q_Factors)\n",
    "combined_df = pd.concat([FF5M.reset_index(drop=True), Q_Factors.reset_index(drop=True)], axis=1)\n",
    "\n",
    "# Display the combined DataFrame\n",
    "print(combined_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Method 1: Using csv writer\n",
    "with open('data\\Factors.csv', 'w', newline='') as file:\n",
    "    writer = csv.writer(file)\n",
    "    # Write headers\n",
    "    writer.writerow(combined_df.columns)\n",
    "    # Write data\n",
    "    writer.writerows(combined_df.values)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
